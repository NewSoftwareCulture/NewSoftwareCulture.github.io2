<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Заметки по DataScince</title>
</head>
<body>
    <div>
        <h2>Выбор функции активации</h2>
        <b>Классический</b> алгоритм обратного распространения ошибки хорошо работает на <b>двухслойных и трехслойных</b> нейронных сетях, 
        но при дальнейшем увеличении глубины начинает испытывать проблемы. Одна из причин — так называемое затухание градиентов.
    </div>
    <div>
        По скорости обучения можно судить о соответствии выборки и нейронной сети:
        • Если нейронная сеть будет слишком сложна, то она быстро переобучится, как, например, показывает
        желтая линия.
        • Если выборка будет сложна или сильно зашумлена для нейронной сети, то нейронная сеть будет обучаться медленно, как показывает синяя линия.
        • Если выборка по сложности соответствует нейронной сети, то, скорее всего, мы увидим красную линию
        — хорошую скорость обучения.
        • Важно также следить за разницей между значениями функции ошибки на обучении и на контроле. Эта
        разница не должна быть существенной. Если она велика, то это значит, что нейронная сеть переобучилась и следует изменить ее сложность.
    </div>
</body>
</html>